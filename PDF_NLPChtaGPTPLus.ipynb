{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemantam1/WebScraping/blob/ChatGPTPlus/PDF_NLPChtaGPTPLus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMcPpBifZ2uE",
        "outputId": "af022bdf-e9dc-4cdb-ef2b-7418a00b8b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google_play_scraper\n",
            "  Downloading google_play_scraper-1.2.4-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google_play_scraper\n",
            "Successfully installed google_play_scraper-1.2.4\n"
          ]
        }
      ],
      "source": [
        "!pip install google_play_scraper\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scrapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpBa8yLnJNw_",
        "outputId": "61d23825-fcd8-42f5-b01c-caf69ec9fb6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scrapy\n",
            "  Downloading Scrapy-2.9.0-py2.py3-none-any.whl (277 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m277.2/277.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Twisted>=18.9.0 (from scrapy)\n",
            "  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.4.6 in /usr/local/lib/python3.10/dist-packages (from scrapy) (40.0.2)\n",
            "Collecting cssselect>=0.9.1 (from scrapy)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting itemloaders>=1.0.1 (from scrapy)\n",
            "  Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting parsel>=1.5.0 (from scrapy)\n",
            "  Downloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting pyOpenSSL>=21.0.0 (from scrapy)\n",
            "  Downloading pyOpenSSL-23.1.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting queuelib>=1.4.2 (from scrapy)\n",
            "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting service-identity>=18.1.0 (from scrapy)\n",
            "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting w3lib>=1.17.0 (from scrapy)\n",
            "  Downloading w3lib-2.1.1-py3-none-any.whl (21 kB)\n",
            "Collecting zope.interface>=5.1.0 (from scrapy)\n",
            "  Downloading zope.interface-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protego>=0.1.15 (from scrapy)\n",
            "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting itemadapter>=0.1.0 (from scrapy)\n",
            "  Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from scrapy) (67.7.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from scrapy) (23.1)\n",
            "Collecting tldextract (from scrapy)\n",
            "  Downloading tldextract-3.4.4-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from scrapy) (4.9.2)\n",
            "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
            "  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.6->scrapy) (1.15.1)\n",
            "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from protego>=0.1.15->scrapy) (1.16.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (23.1.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.3.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.10/dist-packages (from service-identity>=18.1.0->scrapy) (0.5.0)\n",
            "Collecting constantly>=15.1 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting incremental>=21.3.0 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting Automat>=0.8.0 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting hyperlink>=17.1.1 (from Twisted>=18.9.0->scrapy)\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from Twisted>=18.9.0->scrapy) (4.5.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.4)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (2.27.1)\n",
            "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->scrapy) (3.12.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.6->scrapy) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.12)\n",
            "Installing collected packages: PyDispatcher, incremental, constantly, zope.interface, w3lib, queuelib, protego, jmespath, itemadapter, hyperlink, cssselect, Automat, Twisted, requests-file, parsel, tldextract, service-identity, pyOpenSSL, itemloaders, scrapy\n",
            "Successfully installed Automat-22.10.0 PyDispatcher-2.0.7 Twisted-22.10.0 constantly-15.1.0 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 parsel-1.8.1 protego-0.2.1 pyOpenSSL-23.1.1 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.9.0 service-identity-21.1.0 tldextract-3.4.4 w3lib-2.1.1 zope.interface-6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "\n",
        "class ReviewsSpider(scrapy.Spider):\n",
        "    name = 'reviews'\n",
        "    allowed_domains = ['play.google.com']\n",
        "\n",
        "    def start_requests(self):\n",
        "        app_link = 'https://play.google.com/store/apps/details?id=com.taxsee.taxsee&gl=kw&hl=en&hl=en&gl=us'\n",
        "        yield scrapy.Request(url=f'{app_link}&showAllReviews=true', callback=self.parse)\n",
        "\n",
        "    def parse(self, response):\n",
        "        reviews = response.css('div.UD7Dzf::text').getall()\n",
        "        for review in reviews:\n",
        "            yield {'review': review}"
      ],
      "metadata": {
        "id": "8z0B3i4JIAkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrapy crawl reviews -o reviews.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "nZuysNonLDbw",
        "outputId": "70e70cc4-9eee-49b8-f5f6-1fe1dcb7b2aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-2c6e9f3ee466>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    scrapy crawl reviews -o reviews.json\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5kx68UylPKs",
        "outputId": "d3c40a4f-5652-439b-cf64-2214e084ec82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting reviews\n",
            "  Downloading reviews-0.6.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click==8.1.3 in /usr/local/lib/python3.10/dist-packages (from reviews) (8.1.3)\n",
            "Collecting humanize==4.5.0 (from reviews)\n",
            "  Downloading humanize-4.5.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from reviews) (3.4)\n",
            "Collecting keyboard==0.13.5 (from reviews)\n",
            "  Downloading keyboard-0.13.5-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyGithub==1.57 (from reviews)\n",
            "  Downloading PyGithub-1.57-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-decouple==3.7 (from reviews)\n",
            "  Downloading python_decouple-3.7-py3-none-any.whl (9.9 kB)\n",
            "Collecting python-gitlab==3.13.0 (from reviews)\n",
            "  Downloading python_gitlab-3.13.0-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.4/134.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich==13.3.1 (from reviews)\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m239.0/239.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated (from PyGithub==1.57->reviews)\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting pyjwt>=2.4.0 (from PyGithub==1.57->reviews)\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub==1.57->reviews)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from PyGithub==1.57->reviews) (2.27.1)\n",
            "Collecting requests-toolbelt>=0.10.1 (from python-gitlab==3.13.0->reviews)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.3.1->reviews) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.3.1->reviews) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich==13.3.1->reviews) (0.1.2)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGithub==1.57->reviews) (1.15.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub==1.57->reviews) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub==1.57->reviews) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGithub==1.57->reviews) (2.0.12)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->PyGithub==1.57->reviews) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub==1.57->reviews) (2.21)\n",
            "Installing collected packages: python-decouple, keyboard, pyjwt, humanize, deprecated, rich, requests-toolbelt, pynacl, python-gitlab, PyGithub, reviews\n",
            "  Attempting uninstall: humanize\n",
            "    Found existing installation: humanize 4.6.0\n",
            "    Uninstalling humanize-4.6.0:\n",
            "      Successfully uninstalled humanize-4.6.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.3.4\n",
            "    Uninstalling rich-13.3.4:\n",
            "      Successfully uninstalled rich-13.3.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.6.9 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyGithub-1.57 deprecated-1.2.13 humanize-4.5.0 keyboard-0.13.5 pyjwt-2.7.0 pynacl-1.5.0 python-decouple-3.7 python-gitlab-3.13.0 requests-toolbelt-1.0.0 reviews-0.6.0 rich-13.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOdkzfWFlbUw",
        "outputId": "6e669061-ab7d-4779-a649-84cc79ca07a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.3.25)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from jax) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax) (1.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from jax) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jax 0.4.2\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY1Yyip2ls15",
        "outputId": "da9d1e92-fb60-4b44-9d3c-bd76fabcb87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.3.25)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement 0.4.2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for 0.4.2\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google_play_scraper import app\n",
        "from google_play_scraper import Sort, reviews_all\n",
        "\n",
        "def extract_reviews_by_date(app_id, target_date):\n",
        "    reviews = []\n",
        "    count = 0\n",
        "    batch_size = 100\n",
        "    page_token = None\n",
        "\n",
        "    while True:\n",
        "      result = reviews_all(\n",
        "            app_id,\n",
        "            lang='en',  # Language code for the reviews\n",
        "            country='us',  # Country code for the reviews\n",
        "            sort=Sort.NEWEST,  # Sorting order of the reviews\n",
        "            count=batch_size,\n",
        "            filter_score_with=None,\n",
        "            page_token=page_token\n",
        "        )\n",
        "\n",
        "      for review in result['reviews']:\n",
        "        review_date = review['at']\n",
        "        if review_date >= target_date:\n",
        "          reviews.append(review['content'])\n",
        "          count += 1\n",
        "          page_token = result.get('paginationToken')\n",
        "\n",
        "        if count >= result['numReviews'] or not page_token:\n",
        "          break\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# Example usage\n",
        "app_id = 'com.eterno'\n",
        "target_date = '2023-01-01'  # Target date in the format 'YYYY-MM-DD'\n",
        "reviews = extract_reviews_by_date(app_id, target_date)\n",
        "\n",
        "for i, review in enumerate(reviews, 1):\n",
        "    print(f\"Review {i}: {review}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "pg4zWblLkoqh",
        "outputId": "403d5634-7bff-467c-b333-0e260a99d27a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3007a981bfc4>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mapp_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'com.eterno'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtarget_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2023-01-01'\u001b[0m  \u001b[0;31m# Target date in the format 'YYYY-MM-DD'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_reviews_by_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-3007a981bfc4>\u001b[0m in \u001b[0;36mextract_reviews_by_date\u001b[0;34m(app_id, target_date)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       result = reviews_all(\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mapp_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Language code for the reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google_play_scraper/features/reviews.py\u001b[0m in \u001b[0;36mreviews_all\u001b[0;34m(app_id, sleep_milliseconds, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         _result, continuation_token = reviews(\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0mapp_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_COUNT_EACH_FETCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: reviews() got an unexpected keyword argument 'page_token'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u53ON9VgaAWB",
        "outputId": "90005a7a-626b-4a7b-d411-22186493545c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "410411\n",
            "['good', 'becouse true news avelable here', 'excellent', 'Good', 'OK', 'good', 'hahwus', 'very good', 'best', 'good', 'super', 'n vg', 'good', 'Uninstall. The developer do not understand the fact that there may be few regional Applications on Play Store. Changing language and region on your phone do not allow you to access an Application from different Countries.', 'ok', 'best', 'News are good but hanged and not responding sooner,, very poor condition', 'very good', 'good', 'iwantdailyhunt is now', 'Good information provided daily.', 'After the xpresso update it is lagging always', 'good', \"umm it's good but there should be a long information to about the incidents\", 'good', 'super', 'super', 'Informative app', '‡∞®‡∞æ‡∞∞‡∞æ‡∞Ø‡∞£', 'very good', \"Question 7708 Rev 6 and 4 and I 4 and z.243335 York l I'm 4 Dez5999449 Free 7855?? 3/do He'd/5 years r/56555 Red 66 You64z4g4/ Red\", 'very good', 'Good', 'good', 'excellent app. this app gives me every thing.', 'vini', 'Good', 'Avoid unnecessary information', 'good', 'okay', 'nc', 'I using before 2yers this app great', 'best', 'Goma rasaili', 'good', \"Great app in terms of news that they provide but the UI seems very clunky. It'd be great if the news view was simplified.\", 'KOLLam ishttamay', 'Nice app', 'best', '‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•à', 'very nice', '‡§Ö‡§ö‡•ç‡§õ‡§æ', 'S AA ea we a as Zee s', 'good', '‡≤∏‡≥Ç‡≤™‡≤∞‡≥ç', 'ÿ®€Åÿ™ ÿß⁄Ü⁄æÿß', 'SZzrr*2‚Çπ3<`$rss Ke D don ew', 'U u. Uh', 'News Paper', 'üôèüôèüôè', 'super', 'good üëç', 'nice', 'nice', 'goog', 'Worest news app.. Useless news', 'Absolutely fantastic. all types news are available here. I like Dailyhunt.....', 'very nice', '‡¶≠‡¶æ‡¶≤‡ßã', 'good', 'disappointed with spelling mistakes', 'good', 'good', 'very good', 'superb', 'good', 'gphui', 'very nice üëçüëçüëçüëçüëç and very good app', 'Hinf', 'üëåüôè', 'very good', 'very good', 'very nice', 'Last one month worst app in my phone.if any platform availlable i will s delete it', 'good', 'very useful informations', 'good', 'Nice', \"IT'S THE BEST üëå\", 'best', 'Amazing app for news....Recently I have been going through Karnataka state election results ... In which it also shows previous results vs currect election results which is very much informative and useful for common people.... Good creativity', 'Very bad', 'right', 'very good', 'superd', 'very good', 'this app is bettar for news', 'good', 'wini', 'good']\n"
          ]
        }
      ],
      "source": [
        "from google_play_scraper import app\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# US Market\n",
        "\n",
        "from google_play_scraper import Sort, reviews_all\n",
        "\n",
        "us_reviews = reviews_all(\n",
        "    #'com.omega.taxi',\n",
        "    # 'com.facebook.katana',\n",
        "    'com.eterno',\n",
        "    sleep_milliseconds=0,  # defaults to 0\n",
        "    lang='en',  # defaults to 'en'\n",
        "    country='kw',  # defaults to 'us'\n",
        "    sort=Sort.NEWEST,  # defaults to Sort.MOST_RELEVANT\n",
        ")\n",
        "\n",
        "# Concatenated list (list of list)\n",
        "df_autoveh = pd.DataFrame(np.array(us_reviews), columns=['review'])\n",
        "df_autoveh = df_autoveh.join(pd.DataFrame(\n",
        "    df_autoveh.pop('review').tolist()))  # to dataframe\n",
        "\n",
        "# Dropping last n rows using drop\n",
        "n = 50000\n",
        "df_autoveh.drop(df_autoveh.tail(n).index, inplace=True)\n",
        "\n",
        "# print(len(us_reviews))\n",
        "# print(type(us_reviews))\n",
        "# print(df_autoveh.head())\n",
        "rev_list1 = df_autoveh['content'].tolist()\n",
        "print(len(rev_list1))\n",
        "rev_list = rev_list1[0:88]\n",
        "print(rev_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4jaygjOxRV48",
        "outputId": "df5a6c73-6e33-477a-fbdd-0a58b6412404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "460598\n"
          ]
        }
      ],
      "source": [
        "from google_play_scraper import app\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# US Market\n",
        "\n",
        "from google_play_scraper import Sort, reviews_all\n",
        "\n",
        "\n",
        "us_reviews = reviews_all(\n",
        "    #'com.omega.taxi',  47\n",
        "    'com.eterno',\n",
        "    sleep_milliseconds=0,  # defaults to 0\n",
        "    lang='en',  # defaults to 'en'\n",
        "    country='kw',  # defaults to 'us'\n",
        "    count=100,\n",
        "    sort=Sort.NEWEST,  # defaults to Sort.MOST_RELEVANT\n",
        ")\n",
        "\n",
        "df_autoveh = pd.DataFrame(np.array(us_reviews), columns=['review'])  # Concatenated list (list of list)\n",
        "df_autoveh = df_autoveh.join(pd.DataFrame(df_autoveh.pop('review').tolist()))  # to dataframe\n",
        "print(type(us_reviews))\n",
        "df_autoveh.head()\n",
        "print(len(df_autoveh))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzmNIfnWKvRp",
        "outputId": "2784e062-2584-4773-ef4f-058aad39d361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIwiK299K4xu",
        "outputId": "453424c7-016f-4f8c-a9ba-f5b563bef88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "0hyKBsmLKOEt",
        "outputId": "5976a9aa-a61e-483f-d808-34f5af7cdc11"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-03b5f3c81d5a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyPDF2\u001b[0m  \u001b[0;31m# for PDF file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle_play_scraper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle_play_scraper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google_play_scraper'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#Install and import required libraries\n",
        "import openai\n",
        "import PyPDF2  # for PDF file\n",
        "import google_play_scraper\n",
        "from google_play_scraper import app\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Initialize chatGPT API Key\n",
        "#  raise self.handle_error_response(\n",
        "#  openai.error.AuthenticationError: <empty message> , We have to verify the existance of already generated API_Key,\n",
        "#  If key is expired then we need to create new one.\n",
        "#API_KEY = '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'\n",
        "API_KEY = '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'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "\n",
        "# function to convert PDF to text\n",
        "def PDF2text(filename):\n",
        "\n",
        "    # Open the PDF file\n",
        "    file = open(filename, 'rb')\n",
        "\n",
        "    # Read the PDF file\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    # Get the number of pages in the PDF file\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    # Extract text from each page of the PDF file\n",
        "    text = \"\"\n",
        "    for i in range(num_pages):\n",
        "      page = reader.pages[i]\n",
        "      text += page.extract_text()\n",
        "      return (text)  # print(text)\n",
        "\n",
        "\n",
        "input_text = PDF2text('/content/Australia_cybersecuritystrategy.pdf')\n",
        "\n",
        "\n",
        "# Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,  # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "\n",
        "# Sentiment Analysis\n",
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a text\\ \n",
        "\n",
        "Summarize the text below, delimited by triple \\\n",
        "backticks in at most 150 words. \n",
        "\n",
        "Review: ```{input_text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLP on WorkPlace safety and Health"
      ],
      "metadata": {
        "id": "JfuSbUx47iKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7FpeKsWgEKk",
        "outputId": "78431539-ec03-4d9f-b2ee-9d0b10f295bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcnMJDLSgIxE",
        "outputId": "b330c933-88eb-4750-b613-568d6d1d8092"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install and import required libraries\n",
        "import openai\n",
        "import PyPDF2  # for PDF file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Initialize chatGPT API Key\n",
        "#  raise self.handle_error_response(\n",
        "#  openai.error.AuthenticationError: <empty message> , We have to verify the existance of already generated API_Key,\n",
        "#  If key is expired then we need to create new one.\n",
        "#API_KEY = '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'\n",
        "#API_KEY = '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'\n",
        "API_KEY = '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'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "\n",
        "# function to convert PDF to text\n",
        "def PDF2text(filename):\n",
        "\n",
        "    # Open the PDF file\n",
        "    file = open(filename, 'rb')\n",
        "\n",
        "    # Read the PDF file\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    # Get the number of pages in the PDF file\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    # Extract text from each page of the PDF file\n",
        "    text = \"\"\n",
        "    for i in range(num_pages):\n",
        "      page = reader.pages[i]\n",
        "      text += page.extract_text()\n",
        "      return (text)  # print(text)\n",
        "\n",
        "\n",
        "input_text = PDF2text('/content/Australian_WHS.pdf')\n",
        "\n",
        "\n",
        "# Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,  # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "\n",
        "# Summary Analysis\n",
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a text\\ \n",
        "\n",
        "Summarize the text below, delimited by triple \\\n",
        "backticks in at most 150 words. \n",
        "\n",
        "Review: ```{input_text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDbUMaL_7Udv",
        "outputId": "2c5ddb70-09fd-4639-b739-eb218532437a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Australian government has released a new Work Health and Safety (WHS) Strategy for the years 2023-2033. The strategy aims to improve the health and safety of workers across the country by focusing on four key areas: leadership and culture, capability and capacity, innovation and research, and national consistency. The strategy also includes a focus on mental health and wellbeing in the workplace, as well as addressing emerging risks such as climate change and technological advancements. The government hopes that the strategy will help to reduce the number of work-related injuries and illnesses in Australia, which currently costs the economy billions of dollars each year. The strategy was developed in consultation with a range of stakeholders, including employers, workers, and industry groups.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keywords Extraction\n"
      ],
      "metadata": {
        "id": "1PUCBJ0BlMtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install and import required libraries\n",
        "import openai\n",
        "import PyPDF2  # for PDF file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Initialize chatGPT API Key\n",
        "#  raise self.handle_error_response(\n",
        "#  openai.error.AuthenticationError: <empty message> , We have to verify the existance of already generated API_Key,\n",
        "#  If key is expired then we need to create new one.\n",
        "#API_KEY = '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'\n",
        "#API_KEY = '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'\n",
        "API_KEY = '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'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "\n",
        "# function to convert PDF to text\n",
        "def PDF2text(filename):\n",
        "\n",
        "    # Open the PDF file\n",
        "    file = open(filename, 'rb')\n",
        "\n",
        "    # Read the PDF file\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    # Get the number of pages in the PDF file\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    # Extract text from each page of the PDF file\n",
        "    text = \"\"\n",
        "    for i in range(num_pages):\n",
        "      page = reader.pages[i]\n",
        "      text += page.extract_text()\n",
        "      return (text)  # print(text)\n",
        "\n",
        "\n",
        "input_text = PDF2text('/content/Australian_WHS.pdf')\n",
        "\n",
        "\n",
        "# Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,  # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "# Summary Analysis\n",
        "prompt = f\"\"\"\n",
        "Your task is to extract the keywords from a text\\ \n",
        "\n",
        "Extract keywords of the text below, delimited by triple \\\n",
        "backticks with 20 words. \n",
        "\n",
        "Review: ```{input_text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVEgfWnbgW0M",
        "outputId": "9cebf1fb-3538-4a10-8e71-3fc328873bd1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Australian, Work Health, Safety, WHS, Strategy, 2023, 2033.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extract the Policy information related to Sexual harassment"
      ],
      "metadata": {
        "id": "vROGVBConVwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LEAvhLXmujn",
        "outputId": "dfa6f4d2-0263-4bf7-e045-b1bbdca3904d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSPRx_Mtm8dd",
        "outputId": "3ce50aa8-7b4f-4b71-ead0-8e1d2808eec0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install and import required libraries\n",
        "import openai\n",
        "import PyPDF2  # for PDF file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Initialize chatGPT API Key\n",
        "#  raise self.handle_error_response(\n",
        "#  openai.error.AuthenticationError: <empty message> , We have to verify the existance of already generated API_Key,\n",
        "#  If key is expired then we need to create new one.\n",
        "#API_KEY = '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'\n",
        "#API_KEY = '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'\n",
        "API_KEY = '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'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "\n",
        "# function to convert PDF to text\n",
        "def PDF2text(filename):\n",
        "\n",
        "    # Open the PDF file\n",
        "    file = open(filename, 'rb')\n",
        "\n",
        "    # Read the PDF file\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    # Get the number of pages in the PDF file\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    # Extract text from each page of the PDF file\n",
        "    text = \"\"\n",
        "    for i in range(num_pages):\n",
        "      page = reader.pages[i]\n",
        "      text += page.extract_text()\n",
        "      return (text)  # print(text)\n",
        "\n",
        "\n",
        "input_text = PDF2text('/content/Australian_WHS.pdf')\n",
        "\n",
        "\n",
        "# Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,  # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "# Summary Analysis\n",
        "prompt = f\"\"\"\n",
        "Your task is to extract the information related\\ \n",
        "to policies for sexual harassment\\\n",
        "\n",
        "Extract the sexual harassment policy information\\\n",
        "of the text below, delimited by triple \\\n",
        "backticks with 50 words. \n",
        "\n",
        "Review: ```{input_text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaItAuKQmIWB",
        "outputId": "733d1c02-7c80-43e1-c0d1-3bd3e70cbab8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is no information related to policies for sexual harassment in the given text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Policy information related to women safety at work place"
      ],
      "metadata": {
        "id": "qtOdU2Bv7XDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeyHin0En1pk",
        "outputId": "71858043-ef92-43ea-d085-69f0983b391a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkZZeJ0Un6e_",
        "outputId": "b4e0afac-401e-4dc1-efe6-1c87a9ad4725"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install and import required libraries\n",
        "import openai\n",
        "import PyPDF2  # for PDF file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Initialize chatGPT API Key\n",
        "#  raise self.handle_error_response(\n",
        "#  openai.error.AuthenticationError: <empty message> , We have to verify the existance of already generated API_Key,\n",
        "#  If key is expired then we need to create new one.\n",
        "#API_KEY = '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'\n",
        "#API_KEY = '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'\n",
        "API_KEY = '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'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "\n",
        "# function to convert PDF to text\n",
        "def PDF2text(filename):\n",
        "\n",
        "    # Open the PDF file\n",
        "    file = open(filename, 'rb')\n",
        "\n",
        "    # Read the PDF file\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    # Get the number of pages in the PDF file\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    # Extract text from each page of the PDF file\n",
        "    text = \"\"\n",
        "    for i in range(num_pages):\n",
        "      page = reader.pages[i]\n",
        "      text += page.extract_text()\n",
        "      return (text)  # print(text)\n",
        "\n",
        "\n",
        "input_text = PDF2text('/content/Australian_WHS.pdf')\n",
        "\n",
        "\n",
        "# Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,  # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "# Summary Analysis\n",
        "prompt = f\"\"\"\n",
        "Your task is to extract the information related\\ \n",
        "to policies for women safety\\\n",
        "\n",
        "Extract the women safety policy information\\\n",
        "of the text below, delimited by triple \\\n",
        "backticks with 50 words. \n",
        "\n",
        "Review: ```{input_text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUSRvOtwnrtS",
        "outputId": "645115ac-4624-4336-bd8b-afcb4b9cc32e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is no information related to policies for women safety in the given text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Policy information related to mental health"
      ],
      "metadata": {
        "id": "I1VCZzCWoMe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtVph7UloVJj",
        "outputId": "e2e09385-85ff-413e-a57c-78a64095ae7a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLcxF0Kaon1M",
        "outputId": "05d512a8-8faa-4972-de31-2be68dad7d49"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install and import required libraries\n",
        "import openai\n",
        "import PyPDF2  # for PDF file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Initialize chatGPT API Key\n",
        "#  raise self.handle_error_response(\n",
        "#  openai.error.AuthenticationError: <empty message> , We have to verify the existance of already generated API_Key,\n",
        "#  If key is expired then we need to create new one.\n",
        "#API_KEY = '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'\n",
        "#API_KEY = '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'\n",
        "API_KEY = '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'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "\n",
        "# function to convert PDF to text\n",
        "def PDF2text(filename):\n",
        "\n",
        "    # Open the PDF file\n",
        "    file = open(filename, 'rb')\n",
        "\n",
        "    # Read the PDF file\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    # Get the number of pages in the PDF file\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    # Extract text from each page of the PDF file\n",
        "    text = \"\"\n",
        "    for i in range(num_pages):\n",
        "      page = reader.pages[i]\n",
        "      text += page.extract_text()\n",
        "      return (text)  # print(text)\n",
        "\n",
        "\n",
        "input_text = PDF2text('/content/Australian_WHS.pdf')\n",
        "\n",
        "\n",
        "# Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,  # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "# Summary Analysis\n",
        "prompt = f\"\"\"\n",
        "Your task is to extract the information related\\ \n",
        "to policies for mental illness\\\n",
        "\n",
        "Extract the mental illness policy information\\\n",
        "of the text below, delimited by triple \\\n",
        "backticks with 50 words. \n",
        "\n",
        "Review: ```{input_text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d0017f-1c8e-4f28-d60e-cc09683721d1",
        "id": "Es6JWSk6oa6w"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is no information related to policies for mental illness in the given text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4PoMi9qKTL_"
      },
      "source": [
        "# App reviews into list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV-Ith79ThlM",
        "outputId": "0d1196bc-bb87-4e9d-a1fa-de79fe5d28bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "4xLPxAgRS1Kq",
        "outputId": "5188cddd-00c4-46cb-8805-d6092e80186c"
      },
      "outputs": [
        {
          "ename": "BadZipFile",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e39599e8facf>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Get each category in excel file and each app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Playstore.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mappids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'appId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mappids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0;31m# Workaround for some third party files that use forward slashes and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0;31m# lower case names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from google_play_scraper import app\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openpyxl\n",
        "# US Market\n",
        "\n",
        "from google_play_scraper import Sort, reviews_all\n",
        "# API_KEY = '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'\n",
        "API_KEY = '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'\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "\n",
        "# , 'BEAUTY', 'BUSINESS', 'COMICS', 'COMMUNICATION', 'DATING', 'EDUCATION', 'ENTERTAINMENT', 'EVENTS', 'FINANCE', 'FOOD-AND-DRINK', 'LIFESTYLE', 'MAPS_AND_NAVIGATION', 'MEDICAL', 'MUSIC_AND_AUDIO',\n",
        "category_list = ['ART_AND_DESIGN', 'AUTO_AND_VEHICLES']\n",
        "# 'NEWS_AND_MAGAZINES', 'PARENTING', 'PERSONALIZATION', 'PHOTOGRAPHY', 'PRODUCTIVITY', 'SHOPPING', 'SOCIAL', 'SPORTS', 'LIBRARIES_AND_DEMO', 'BOOKs_AND_REFERENCE', 'HEALTH_AND_FITNESS', 'HOUSE_AND_HOME', 'WEATHER', 'TRAVEL_AND_LOCAL', 'VIDEO_PLAYERS', 'TOOLS']\n",
        "# print(len(category_list))\n",
        "\n",
        "\n",
        "# Get each category in excel file and each app\n",
        "for category in category_list:\n",
        "    df = pd.read_excel('/content/Playstore.xlsx', sheet_name=category)\n",
        "    appids = df['appId'].tolist()\n",
        "    appids = appids[0:2]\n",
        "    # print(appids)\n",
        "    # print(len(appids))  #Number of apps\n",
        "    # No_of_apps = len(appids)\n",
        "    for eachappid in appids:\n",
        "        print(eachappid)\n",
        "        urlid = eachappid.partition('&gl=')[0]  # print(urlid)\n",
        "        print(urlid)\n",
        "        us_reviews = reviews_all(\n",
        "            urlid,\n",
        "            sleep_milliseconds=0,  # defaults to 0\n",
        "            lang='en',  # defaults to 'en'\n",
        "            country='kw',  # defaults to 'us'\n",
        "            sort=Sort.NEWEST,  # defaults to Sort.MOST_RELEVANT\n",
        "        )\n",
        "\n",
        "# Concatenated list (list of list)\n",
        "        df_autoveh = pd.DataFrame(np.array(us_reviews), columns=['review'])\n",
        "        df_autoveh = df_autoveh.join(pd.DataFrame(\n",
        "            df_autoveh.pop('review').tolist()))  # to dataframe\n",
        "       # print(type(us_reviews))\n",
        "       # print(df_autoveh.head())\n",
        "\n",
        "        rev_list1 = df_autoveh['content'].tolist()\n",
        "        if len(rev_list1) < 88:\n",
        "            rev_list = rev_list1[0:len(rev_list1)]\n",
        "        else:\n",
        "            rev_list = rev_list1[0:88]\n",
        "        # print(len(rev_list))\n",
        "        print(rev_list)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBGd0iuwlFKZ9m/rGYgm1J",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}